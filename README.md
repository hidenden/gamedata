# Japan Game Data Analysis

# データパイプラインの考え方

### 概要

以下の3段階で構成する

- クローリング → 生データ
- データクレンジング → 正規化データ
- 正規化データ → 各種分析データ

## raw: クローリング → 生データ

スクリプトは複数あってもいいが､ "build.py" がエントリーポイントとなるようにする

1. WebからHTMLをクローリングする
2. データの入ったテーブル内の値をえる
3. テーブル内のデータをCSVの形式で保存し生データとする

データソース毎にフォルダを分離する｡
複数のデータソースの統合はtransform層で実施する｡

## transform: データクレンジング → 正規化データ

スクリプトは複数あってもいいが､ "build.py" がエントリーポイントとなるようにする｡
transformには変換過程のデータを配置しても良い｡ データの形式はCSVとする

## processed: 正規化データの格納場所

正規化された､分析に供するデータのみが配置される｡

ここではデータ構造の変換は行わず､transformに格納されたデータの
格納形式変換 (CSV → pkl, CSV → SQLite, CSV → DataFrame)を行うのみとする｡

## analyzed:分析データ

基本データを加工して分析結果のテーブル､ノートブックが格納される

定型的な分析テーブルについては build.pyをエントリーポイントとしたスクリプトで
データが生成されるのが望ましい｡


##
