{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47658da2-d7bd-45bc-b3c7-1f4b1e7bf404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/01 15:16:14 WARN Utils: Your hostname, apricot.local resolves to a loopback address: 127.0.0.1; using 192.168.0.42 instead (on interface en0)\n",
      "23/04/01 15:16:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/01 15:16:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/01 15:16:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/01 15:16:14 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, TimestampType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import japanize_matplotlib\n",
    "\n",
    "# spark initialization\n",
    "spark = SparkSession.builder.appName(\"gamedata\").getOrCreate()\n",
    "# load master database\n",
    "hard_sales = spark.read.parquet(\"../database/parquet/hard_sales\")\n",
    "# hard_info_df = spark.read.parquet(\"../database/parquet/hard_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0f6a10-7ed8-47a1-be08-280197c83c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_launch_df = hard_sales.groupBy(\"delta_week\").pivot(\"hw\").sum(\"sum_units\").sort(\"delta_week\").select(\n",
    "    \"delta_week\",\n",
    "    \"PS5\", \"PS4\", \"PS3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1d4df0-5854-4bf6-b596-23bf6427c97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/01 15:16:18 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+----------+------+------+------+\n",
      "|delta_week|   PS5|   PS4|   PS3|\n",
      "+----------+------+------+------+\n",
      "|         0|118085|322083| 88443|\n",
      "|         1|160976|374780|131821|\n",
      "|         2|201435|405546|169082|\n",
      "|         3|213328|434410|199549|\n",
      "|         4|224384|467751|243146|\n",
      "|         5|241962|491889|313703|\n",
      "|         6|255150|506925|390209|\n",
      "|         7|265782|518978|466715|\n",
      "|         8|276946|532012|534335|\n",
      "|         9|284274|542141|567827|\n",
      "|        10|301622|553833|593206|\n",
      "|        11|327570|562513|614234|\n",
      "|        12|341094|569400|634921|\n",
      "|        13|363984|576787|657871|\n",
      "|        14|389021|583653|678488|\n",
      "|        15|422859|591663|700046|\n",
      "|        16|445408|599014|746970|\n",
      "|        17|483259|605541|773895|\n",
      "|        18|517916|613785|793682|\n",
      "|        19|580211|620896|812073|\n",
      "+----------+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps_launch_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35c988a1-4fcf-47ca-8347-e7ceeb554207",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_launch = ps_launch_df.toPandas().set_index(\"delta_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc462eb6-1aa1-4f34-9912-42ad8c2b4b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='delta_week'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps_launch.plot(figsize=(20, 10), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43c7d24-0094-4998-889b-136728adcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps5_launch_df = ps_launch_df.filter(F.col(\"PS5\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76cbf643-d46d-44fc-86aa-588336a9b18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='delta_week'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps5_launch = ps5_launch_df.toPandas().set_index(\"delta_week\")\n",
    "ps5_launch.plot(figsize=(10, 6), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07eb1e4d-4cb7-4c1b-9b9e-95a8194624f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+\n",
      "|delta_week|    PS5|    PS4|    PS3|\n",
      "+----------+-------+-------+-------+\n",
      "|        81|1678528|1642512|2090505|\n",
      "|        82|1690968|1653070|2100614|\n",
      "|        83|1694003|1659863|2177822|\n",
      "|        84|1703184|1703235|2202656|\n",
      "|        85|1727545|1731832|2221333|\n",
      "|        86|1740906|1757182|2238287|\n",
      "|        87|1753451|1778744|2252295|\n",
      "|        88|1764645|1799594|2264262|\n",
      "|        89|1803981|1832187|2276156|\n",
      "|        90|1827281|1859337|2287081|\n",
      "|        91|1850581|1885809|2298433|\n",
      "|        92|1866236|1910325|2309785|\n",
      "|        93|1891345|1944691|2318074|\n",
      "|        94|1911637|1984980|2328875|\n",
      "|        95|1914501|2045310|2337365|\n",
      "|        96|1925681|2115906|2345415|\n",
      "|        97|1955203|2186502|2353640|\n",
      "|        98|1973279|2224788|2361946|\n",
      "|        99|1978825|2251446|2369481|\n",
      "|       100|1999122|2276271|2375380|\n",
      "+----------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps5_launch_df.filter(F.col(\"delta_week\") > 80).orderBy(F.col(\"delta_week\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b22995-6ca8-4248-9095-8a9b18363c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+-----+----+-----+----------+-----+------------+-----------+---------+----------+----------+---------+----+\n",
      "| hw|begin_date|  end_date|units|year|month|launch_day|maker|   full_name|launch_year|delta_day|delta_week|delta_year|sum_units|week|\n",
      "+---+----------+----------+-----+----+-----+----------+-----+------------+-----------+---------+----------+----------+---------+----+\n",
      "|PS4|2015-10-26|2015-11-01|20850|2015|   11|2014-02-22| SONY|PlayStation4|       2014|      617|        88|         1|  1799594|  44|\n",
      "|PS4|2015-11-02|2015-11-08|32593|2015|   11|2014-02-22| SONY|PlayStation4|       2014|      624|        89|         1|  1832187|  45|\n",
      "|PS4|2015-11-09|2015-11-15|27150|2015|   11|2014-02-22| SONY|PlayStation4|       2014|      631|        90|         1|  1859337|  46|\n",
      "|PS4|2015-11-16|2015-11-22|26472|2015|   11|2014-02-22| SONY|PlayStation4|       2014|      638|        91|         1|  1885809|  47|\n",
      "|PS4|2015-11-23|2015-11-29|24516|2015|   11|2014-02-22| SONY|PlayStation4|       2014|      645|        92|         1|  1910325|  48|\n",
      "|PS4|2015-11-30|2015-12-06|34366|2015|   12|2014-02-22| SONY|PlayStation4|       2014|      652|        93|         1|  1944691|  49|\n",
      "|PS4|2015-12-07|2015-12-13|40289|2015|   12|2014-02-22| SONY|PlayStation4|       2014|      659|        94|         1|  1984980|  50|\n",
      "|PS4|2015-12-14|2015-12-20|60330|2015|   12|2014-02-22| SONY|PlayStation4|       2014|      666|        95|         1|  2045310|  51|\n",
      "|PS4|2015-12-21|2015-12-27|70596|2015|   12|2014-02-22| SONY|PlayStation4|       2014|      673|        96|         1|  2115906|  52|\n",
      "|PS4|2015-12-28|2016-01-03|70596|2016|    1|2014-02-22| SONY|PlayStation4|       2014|      680|        97|         2|  2186502|  53|\n",
      "+---+----------+----------+-----+----+-----+----------+-----+------------+-----------+---------+----------+----------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hard_sales.filter(F.col(\"hw\") == \"PS4\").filter(F.col(\"delta_week\").isin([88, 89, 90, 91,92,93,94,95,96,97])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ac85d9-e3c9-4b84-a22b-ce678739cf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+-----+----+-----+----------+-----+------------+-----------+---------+----------+----------+---------+----+\n",
      "| hw|begin_date|  end_date|units|year|month|launch_day|maker|   full_name|launch_year|delta_day|delta_week|delta_year|sum_units|week|\n",
      "+---+----------+----------+-----+----+-----+----------+-----+------------+-----------+---------+----------+----------+---------+----+\n",
      "|PS5|2022-07-18|2022-07-24|11194|2022|    7|2020-11-12| SONY|PlayStation5|       2020|      619|        88|         2|  1764645|  29|\n",
      "|PS5|2022-07-25|2022-07-31|39336|2022|    7|2020-11-12| SONY|PlayStation5|       2020|      626|        89|         2|  1803981|  30|\n",
      "|PS5|2022-08-01|2022-08-07|23300|2022|    8|2020-11-12| SONY|PlayStation5|       2020|      633|        90|         2|  1827281|  31|\n",
      "|PS5|2022-08-08|2022-08-14|23300|2022|    8|2020-11-12| SONY|PlayStation5|       2020|      640|        91|         2|  1850581|  32|\n",
      "+---+----------+----------+-----+----+-----+----------+-----+------------+-----------+---------+----------+----------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hard_sales.filter(F.col(\"hw\") == \"PS5\").filter(F.col(\"delta_week\").isin([88, 89, 90, 91])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39b9785c-a905-4746-858c-b5c2b83a841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplotの有効そうなオプション\\n\\nxticks sequence\\nValues to use for the xticks.\\nyticks sequence\\nValues to use for the yticks.\\nxlim 2-tuple/list\\nSet the x limits of the current axes.\\nylim 2-tuple/list\\nSet the y limits of the current axes.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plotの有効そうなオプション\n",
    "\n",
    "xticks sequence\n",
    "Values to use for the xticks.\n",
    "yticks sequence\n",
    "Values to use for the yticks.\n",
    "xlim 2-tuple/list\n",
    "Set the x limits of the current axes.\n",
    "ylim 2-tuple/list\n",
    "Set the y limits of the current axes.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d354835-3675-48e5-97be-b7941f72a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks_list=[]\n",
    "for y in range(0, 3500, 500):\n",
    "    xticks_list.append(y)\n",
    "xticks_list.append(936)\n",
    "xticks_list.append(1027)\n",
    "xticks_list = sorted(xticks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d6b26a7-bd0a-4f3f-96e6-e7bd6806a551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps_launch.interpolate(method=\"linear\", limit=4).plot(figsize=(18, 8),\n",
    "                                                     grid=True, \n",
    "                                                     ylim=[0, 11000000],\n",
    "                                                     xticks=xticks_list\n",
    "                                                    )\n",
    "plt.savefig('ps_lifetime.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5298981-28ca-4a23-82c6-d83381216e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "508b344f-ca1d-4b23-a702-3dbb9794ffb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps_launch_500 = ps_launch[ps_launch.index <= 580]\n",
    "ps_launch_500.interpolate(method=\"linear\", limit=4).plot(figsize=(12, 8),\n",
    "                                                     grid=True, \n",
    "                                                     ylim=[0, 3000000])\n",
    "plt.savefig('ps_earlydays.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b538fb9e-4801-41bc-b2b1-75e872ec1530",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f977fa29-bb20-4d7a-9538-ef9beb5ed745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps_launch_800 = ps_launch[ps_launch.index <= 800]\n",
    "ps_launch_800.interpolate(method=\"linear\", limit=4).plot(figsize=(12, 8),\n",
    "                                                     grid=True, \n",
    "                                                     ylim=[0, 3000000])\n",
    "plt.savefig('ps_nearfuture.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36612c81-d012-4e87-9a5e-cdc6a4288427",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3787dc21-5fa8-4275-b2d0-8c197283a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=1253)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date(2017, 7, 29) - datetime.date(2014,2,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdfaf4e7-167d-4ad3-9a69-77e82c9e58ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=936)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date(2016, 9, 15) - datetime.date(2014,2,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f76bfb33-f3b9-4476-8329-cbd54fb9bb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 8, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date(2020, 11, 12) + datetime.timedelta(1000)\n",
    "# スリム期待時期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7396ff9-aa53-4ae8-9c96-61145e7e493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2007, 11, 6, 0, 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime(2006, 11, 11) + datetime.timedelta(360)\n",
    "# PS3 急上昇  なぞ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8103773b-abb8-4d7b-b658-8d04d4f8b7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=1027)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime(2009, 9, 3) - datetime.datetime(2006, 11, 11)\n",
    "# PS3 slim発売"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc18009e-1063-43c4-9e7c-9414714b6863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=1741)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime(2011, 8, 18) - datetime.datetime(2006, 11, 11)\n",
    "# PS3値下げ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d533d437-856a-4b74-b158-7f2220eca15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=557)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date(2015, 9, 2) - datetime.date(2014, 2, 22)  # MGSV ファントムペイン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afacfe29-b0c5-42d4-8b03-346d27891d20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'launch_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m psw_launch \u001b[39m=\u001b[39m launch_sum[[\u001b[39m'\u001b[39m\u001b[39mPS4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPS5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPS3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSwitch\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mdropna(how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m psw_launch\u001b[39m.\u001b[39minterpolate(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m, limit\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mplot(figsize\u001b[39m=\u001b[39m(\u001b[39m13\u001b[39m, \u001b[39m8\u001b[39m), grid\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ylim\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m26000000\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39m'\u001b[39m\u001b[39mps_switch.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'launch_sum' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 01:46:14 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 350304 ms exceeds timeout 120000 ms\n",
      "23/04/02 01:46:14 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/04/02 01:46:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 01:46:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 01:46:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:46:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:46:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:46:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:46:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 01:46:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 01:55:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:55:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:55:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:55:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:55:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:55:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:55:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:55:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:56:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 01:56:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:12:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:13:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:13:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:25:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:25:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:26:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:26:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:26:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:26:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:26:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:26:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:26:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:26:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:26:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:26:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:42:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:42:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:42:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:42:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:42:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:42:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:42:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:42:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:42:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:42:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:57:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:57:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 02:58:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 02:58:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:07:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:07:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:07:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:07:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:07:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:07:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:08:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:08:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:08:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:08:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:24:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:24:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:24:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:24:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:25:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:25:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:25:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:25:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:25:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:25:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:25:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:25:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:26:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:26:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:26:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:26:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:26:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:26:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:27:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:27:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:27:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:27:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:35:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:35:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:35:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:35:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:36:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:36:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:36:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:36:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:51:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:51:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:51:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:51:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:51:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:51:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:52:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:52:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:52:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:52:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/04/02 03:52:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:52:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:52:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:52:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.42:55913\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/04/02 03:52:34 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "psw_launch = launch_sum[['PS4', 'PS5', 'PS3', 'Switch']].dropna(how=\"all\")\n",
    "psw_launch.interpolate(method=\"linear\", limit=2).plot(figsize=(13, 8), grid=True, ylim=[0, 26000000])\n",
    "plt.savefig('ps_switch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865d217-9226-44f3-939d-edfe945d5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfadadfc-ad0f-466d-a21d-188966cde524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/24 23:15:54 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 908517 ms exceeds timeout 120000 ms\n",
      "23/03/24 23:15:54 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "psw_launch[\"Switch\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7bb83-eda6-4915-bc46-534fbd05b002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
