これから､私のpysparkのプログラミングのアシストをお願い致します｡

扱うデータフレームのスキーマーを以下に示します｡

root
 |-- hw: string (nullable = true)
 |-- begin_date: date (nullable = true)
 |-- end_date: date (nullable = true)
 |-- units: integer (nullable = true)
 |-- year: integer (nullable = true)
 |-- month: integer (nullable = true)
 |-- launch_day: date (nullable = true)
 |-- maker: string (nullable = true)
 |-- full_name: string (nullable = true)
 |-- launch_year: integer (nullable = true)
 |-- delta_day: integer (nullable = true)
 |-- delta_week: integer (nullable = true)
 |-- delta_year: integer (nullable = true)
 |-- sum_units: long (nullable = true)
 |-- week: integer (nullable = true)

各カラムの意味を以下に説明します｡

hw  ゲーム機の省略名称
begin_date 集計期間開始日
end_date 集計期間終了日
units その集計期間の販売台数
year 集計期間終了日の年
month 集計期間終了日の月
launch_day そのゲーム機の発売年月日
maker ゲーム機のメーカー
full_name ゲーム機のフルネーム
launch_year そのゲーム機の発売年
delta_day 集計時における発売日からの経過日数
delta_week 集計時における発売日からの経過週数
delta_year 集計時における発売日からの経過年(発売した年は0)
sum_units 発売開始からの累計台数
week 週番号( weekofyear(end_date)の値)

コード生成する際の条件は以下です｡

- データ処理はできるだけpysparkを用いる
- グラフの描画はmatplotlibを用いる
- 必要ならばpandasを用いても良い(得にmatplotlibも用いる際)
- その他にre, datetimeなどのライブラリを用いても良い
- 他に必要なOSSのライブラリがあれば必要に応じてimportして用いて良い

コードを出力する際には､以下のimport行がプログラムの冒頭にあると想定して下さい｡

from pyspark.sql import functions as F
from pyspark.sql.types import FloatType, TimestampType, StringType
from pyspark.sql.window import Window
from pyspark import SparkContext
from pyspark.sql import SparkSession
from pyspark.sql.utils import AnalysisException
import pandas as pd
import datetime
import re
import matplotlib.pyplot as plt
import matplotlib as mpl

データが格納されているDataFrameの名前を hard_salesとして､
以降に述べる処理を行うコードを作成して下さい｡

