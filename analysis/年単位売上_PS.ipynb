{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d0161f-bfde-4631-a7e2-1a0bd567cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, TimestampType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import japanize_matplotlib\n",
    "\n",
    "# spark initialization\n",
    "spark = SparkSession.builder.appName(\"gamedata\").getOrCreate()\n",
    "hard_weekly_df = spark.read.parquet(\"../database/parquet/hard_weekly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee00c6ed-d933-4ab5-b136-0be03156720f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[begin_date: date, end_date: date, hw: string, units: int]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_weekly_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e257a4a3-afb9-4aa9-9fda-fdf7c47b0013",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PlayStation World年単位の集計\n",
    "\n",
    "年単位集計を行うために､yearカラムを追加｡値は end_dateを F.year()で変換する｡\n",
    "なお､1998年のデータは年末だけなので､1999年以後でフィルタする｡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb83dbcf-4fdb-4624-9b45-5d03d9633d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_weekly_year_df = hard_weekly_df.withColumn(\"year\", F.year(F.col(\"end_date\"))).filter(F.col(\"year\") > 1998).filter(F.col(\"year\") < 2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eddc6ce-a9bc-4762-84c1-e7802c06c0b0",
   "metadata": {},
   "source": [
    "## グループ化して集計\n",
    "\n",
    "年(year)ごと､ハード(hw)ごとにグループ化して集計する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77758198-995a-443d-9fbe-b9fec6ff7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_yearly_df = hard_weekly_year_df.groupBy(\"year\", \"hw\").agg(\n",
    "    F.sum(F.col(\"units\")).alias(\"units\")).sort(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cefaa6-4c97-4fa1-baf9-1e10ebf58c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard_yearly_df = hard_weekly_year_df.groupBy(\"year\", \"hw\").sum(\"units\").sort(\"year\")\n",
    "# aliasが通らないので面倒かも"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e2e0486-1174-4fc0-8cb8-df2cfc4079e8",
   "metadata": {},
   "source": [
    "## pivot化\n",
    "\n",
    "pivotを使ってHW名を列に並べる｡縦軸は年｡値はunitsをそのまま用いる｡\n",
    "\n",
    "縦軸にしたいカラムでgroupBy()して､横軸をpivot()に指定する｡\n",
    "HWの表示順を調整するためにselectしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "160a9ecb-4bb6-4375-be58-5292fbc0c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_yearly_pivot = hard_yearly_df.groupBy(\"year\").pivot(\"hw\").sum(\"units\").sort(\"year\").select(\n",
    "    \"year\",\n",
    "    \"PS5\", \"PS4\", \"Vita\", \"PS3\", \"PSP\", \"PS2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16b3b9b2-d8c2-4bc9-b0fe-6be2fcbadbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-------+-------+-------+-------+\n",
      "|year|    PS5|    PS4|   Vita|    PS3|    PSP|    PS2|\n",
      "+----+-------+-------+-------+-------+-------+-------+\n",
      "|1999|   null|   null|   null|   null|   null|   null|\n",
      "|2000|   null|   null|   null|   null|   null|3100793|\n",
      "|2001|   null|   null|   null|   null|   null|3279043|\n",
      "|2002|   null|   null|   null|   null|   null|3719575|\n",
      "|2003|   null|   null|   null|   null|   null|2990421|\n",
      "|2004|   null|   null|   null|   null| 349283|2759422|\n",
      "|2005|   null|   null|   null|   null|2194005|2102273|\n",
      "|2006|   null|   null|   null| 466715|1969360|1554467|\n",
      "|2007|   null|   null|   null|1216482|3038309| 818771|\n",
      "|2008|   null|   null|   null| 991255|3552104| 480804|\n",
      "|2009|   null|   null|   null|1723034|2305627| 253616|\n",
      "|2010|   null|   null|   null|1500658|2704975|  89572|\n",
      "|2011|   null|   null| 402794|1414743|1889805|  56235|\n",
      "|2012|   null|   null| 680893|1332547| 951494|  26201|\n",
      "|2013|   null|   null|1191450| 818803| 419888|   4689|\n",
      "|2014|   null| 925570|1147936| 450304|  83891|   null|\n",
      "|2015|   null|1190336| 920024| 166342|   null|   null|\n",
      "|2016|   null|1790883| 865002|   null|   null|   null|\n",
      "|2017|   null|1935247| 396207|   null|   null|   null|\n",
      "|2018|   null|1695227| 181728|   null|   null|   null|\n",
      "|2019|   null|1196152|  37668|   null|   null|   null|\n",
      "|2020| 255150| 542645|   null|   null|   null|   null|\n",
      "|2021| 968185| 104054|   null|   null|   null|   null|\n",
      "|2022|1154054|  22822|   null|   null|   null|   null|\n",
      "+----+-------+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hard_yearly_pivot.show(30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d55af66a-9adb-45e1-ac4f-0a423ec10737",
   "metadata": {},
   "source": [
    "## pandas変換\n",
    "\n",
    "pandasのplotでグラフ化するためpandasのDFに変換する｡\n",
    "\n",
    "デフォルトだとindexが連番になるので､yearがindexになるようpandas側で調整する｡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d01a30f-0e34-47fe-80bc-2b08dbb9b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_year = hard_yearly_pivot.toPandas().set_index(\"year\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7168d5a6-de61-498c-b18d-7c2fb3ce4f15",
   "metadata": {},
   "source": [
    "## グラフ化\n",
    "\n",
    "面グラフを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc008e62-b1bf-491e-9921-cff39b63f4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='年', ylabel='年間販売台数'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"font.size\"] = 16\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel(\"年間販売台数\")\n",
    "#|ax.set_xticks([2000,2005,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021])\n",
    "ax.ticklabel_format(style='plain')\n",
    "hw_year.plot(figsize=(16,8), ax=ax, \n",
    "             grid=True, kind=\"area\", ylim=[0, 6000000], xlabel=\"年\",\n",
    "             color=('#e0e0f0','#010140', '#40deec', \n",
    "                    '#20408f', '#f0a000', '#0000b0'),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8738fc3f-c972-4105-91df-3941127f265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_yearly_pivot = hard_yearly_df.groupBy(\"year\").pivot(\"hw\").sum(\"units\").sort(\"year\").select(\n",
    "    \"year\",\n",
    "    \"PS5\", \"PS4\", \"PS3\", \"PS2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15e28c2b-9139-4283-9d4b-395c81ea8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_year = cs_yearly_pivot.toPandas().set_index(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a80ad55-fd9e-4f3a-8eb1-8ea976bd4f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/30 03:45:20 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 771862 ms exceeds timeout 120000 ms\n",
      "23/06/30 03:45:21 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/06/30 03:45:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:45:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:45:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:45:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:45:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:45:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:45:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:45:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:50:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:50:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:50:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:50:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:50:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:50:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:51:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:51:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:51:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:51:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:56:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:56:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:56:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:56:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:56:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:56:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:57:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:57:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:57:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:57:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:59:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 03:59:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 03:59:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:00:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:00:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:00:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:00:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:00:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:00:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:16:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:16:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:16:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:16:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:17:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:17:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:17:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:17:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:17:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:17:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:17:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:17:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:17:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:17:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:17:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:17:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:18:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:18:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:18:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:18:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:18:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:18:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:24:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:24:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:24:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:24:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:24:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:24:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:25:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:25:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:25:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:25:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:29:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:29:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:29:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:29:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:30:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:30:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:30:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:30:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:30:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:30:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:46:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:46:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 04:46:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:46:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:46:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:46:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:47:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:47:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:47:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:47:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 04:56:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 05:00:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 05:00:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/30 05:01:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 05:01:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 05:01:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 05:01:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 05:01:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 05:01:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.37:50305\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/30 05:01:22 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "fig, bx = plt.subplots()\n",
    "bx.set_ylabel(\"年間販売台数\")\n",
    "bx.ticklabel_format(style='plain')\n",
    "cs_year.plot(ax=bx, figsize=(16,8), xlabel=\"年\", grid=True, kind=\"area\", ylim=[0, 6000000], color=('#e0e0f0', '#010140', '#20208f', '#4040d0')).minorticks_on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f45ec-c5e5-496a-a22e-a94b634837ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
